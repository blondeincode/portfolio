<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Magdalena Bienias</title>
    <link>https://blondeincode.github.io/portfolio/pl/posts/</link>
    <description>Recent content in Posts on Magdalena Bienias</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl</language>
    <lastBuildDate>Wed, 14 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blondeincode.github.io/portfolio/pl/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Predykcja cen kryptowalut</title>
      <link>https://blondeincode.github.io/portfolio/pl/posts/project4/</link>
      <pubDate>Wed, 14 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blondeincode.github.io/portfolio/pl/posts/project4/</guid>
      <description>Predykcja cen wybranych kryptowalut z wykorzystaniem modelu ARIMA. Kryptowaluty, które zostały przeanalizowane:  Bitcoin, Więcej zostanie dodanych wkrótce.  Project Overview ARIMA (Automatyczna regresywna zintegrowana średnia krocząca) to połączenie 2 modeli: AR (Autoregresja) oraz MA (Średnia krocząca). Posiada 3 hiperparametry:
 p (opóźnienia autoregresyjne) d (kolejność różnicowania) q (średnia krocząca)   które pochodzą odpowiednio z elementów AR, I i MA. Część AR to korelacja między poprzednimi i obecnymi okresami czasu.</description>
    </item>
    
    <item>
      <title>Analiza odejścia klientów telekomunikacyjnych</title>
      <link>https://blondeincode.github.io/portfolio/pl/posts/project3/</link>
      <pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blondeincode.github.io/portfolio/pl/posts/project3/</guid>
      <description>Analiza czynników, które mogą mieć wpływ na odejście klientów od operatora telekomunikacyjnego. Próba przewidywania, którzy klienci mogą zrezygnować z usług operatora.
Przegląd projektu  wygenerowanie podstawowego raportu na temat danych wejściowych za pomocą pandas_profiling; brakujące dane w kolumnie &amp;lsquo;TotalCharges&amp;rsquo; zostały uzupełnione medianą wartości w tej kolumnie; stworzono wizualizacje danych; dane podzielono na dane treningowe (70%) i dane testowe (30%); przetestowano następujące metody uczenia maszynowego: regresja logistyczna, maszyna wektorów nośnych, las losowy, k-najbliższych sąsiadów, drzewo decyzyjne; obliczono prawdopodobieństwo rezygnacji dla każdego klienta.</description>
    </item>
    
    <item>
      <title>Analiza anonimowej próbki danych NFZ o wystąpieniu udaru niedokrwiennego</title>
      <link>https://blondeincode.github.io/portfolio/pl/posts/project2/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blondeincode.github.io/portfolio/pl/posts/project2/</guid>
      <description>Dane zostały pobrane ze strony dane.gov.pl Narodowy Fundusz Zdrowia dysponuje danymi sprawozdawczymi przekazanymi przez podmioty lecznicze. Zbiór danych dotyczy usług refundowanych i leków dla pacjentów, z których część przeszła udar niedokrwienny. Zbiór został przygotowany w taki sposób, aby dane o świadczeniach i lekach pochodziły z okresu dwóch lat (t, t + 1), natomiast informacja o wystąpieniu udaru dotyczy okresu najbliższych dwóch lat (t + 2, t + 3). Dostarczony zestaw danych składa się z 6 tabel zawierających aktualne, zanonimizowane dane Narodowego Funduszu Zdrowia.</description>
    </item>
    
    <item>
      <title>Analiza sentymentu i wyszukiwanie najczęściej używanych słów w tweetach Donalda Trumpa</title>
      <link>https://blondeincode.github.io/portfolio/pl/posts/project1/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blondeincode.github.io/portfolio/pl/posts/project1/</guid>
      <description>Opis projektu  dane zostały pobrane ze strony internetowej www.thetrumparchive.com; analiza została przeprowadzona na tweetach publikowanych od 20.01.2017 do 31.12.2020; przeanalizowano tylko tweety w języku angielskim; analiza sentymentu została przeprowadzona z wykorzystaniem biblioteki TextBlob; modelowanie tematyczne zostało przeprowadzone przy użyciu Latent Dirichlet Allocation (LDA).  Po odzyskaniu danych musiałam je wyczyścić, aby można było je wykorzystać do analizy. Wprowadziłam następujące zmiany i utworzyłam następujące zmienne:
 Utworzono kolumny zawierające hashatgi, wzmianki, retweety; Aby usunąć tekst, usunięto linki, znaki interpunkcyjne, cyfry, ikony emoji, wielokrotne spacje i znaki „@”, „#”, „RT”; Usunięto tweety bez tekstu; Zidentyfikowano języki, w których napisano tweety; Tweety zostały poddane tokenizacji, lematyzacji i usunięto stopwords.</description>
    </item>
    
  </channel>
</rss>
